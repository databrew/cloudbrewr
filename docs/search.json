[{"path":"/articles/cloudbrewr-intro.html","id":"log-in-to-aws-databrew","dir":"Articles","previous_headings":"","what":"Log in to AWS @DataBrew","title":"CloudBrewR S3 Introduction","text":"running login, depending session two login types. Interactive Session (RStudio, RSession): Function trigger SSO login DataBrew AWS Portal Bash / EC2 / Containers: Function prompt user export access keys directly ourDataBrew AWS Portal. representative production data pipeline uses IAM Roles","code":"aws_login()"},{"path":"/articles/cloudbrewr-intro.html","id":"get-an-object-from-s3","dir":"Articles","previous_headings":"","what":"Get an Object from S3","title":"CloudBrewR S3 Introduction","text":"Running object getter give user metadata object, starting item size content_length, version_id, s3-related information. read .csv file locally run:","code":"aws_s3_get_object(   bucket = 'databrew.org',    key = 'bohemiatesting-ke/raw-form/reconhh/reconhh.csv') #> $bucket #> databrew.org #>  #> $object_key #> [1] \"bohemiatesting-ke/raw-form/reconhh/reconhh.csv\" #>  #> $last_modified #> [1] \"2022-11-30 00:00:34 GMT\" #>  #> $content_length #> [1] 3089 #>  #> $version_id #> [1] \"gsSHUQeAfyWCpoApw5YKujw98FHT6MxW\" #>  #> $content_type #> [1] \"binary/octet-stream\" #>  #> $etag #> [1] \"\\\"ab1be5f1476a9a687165fe655fc2d53d\\\"\" #>  #> $file_path #> [1] \"/var/folders/87/8tlm2bkn3j55c1rbsygmzdh80000gn/T//Rtmp7Q6TRT/reconhh9b4e7eed2d9e.csv\"  object <- aws_s3_get_object(   bucket = 'databrew.org',    key = 'bohemiatesting-ke/raw-form/reconhh/reconhh.csv') data <- fread(object$file_path) %>%    dplyr::select(SubmissionDate) %>%   head(5) data #>         SubmissionDate #> 1: 2022-07-04 19:53:41 #> 2: 2022-07-04 12:53:50 #> 3: 2022-07-04 12:36:28 #> 4: 2022-07-04 12:22:13 #> 5: 2022-06-29 04:02:33"},{"path":"/articles/cloudbrewr-intro.html","id":"storing-an-object-to-s3-bucket","dir":"Articles","previous_headings":"","what":"Storing an Object to S3 bucket","title":"CloudBrewR S3 Introduction","text":"Say want save output S3, procedure store data:","code":"tempfile <- tempfile(fileext = \".csv\") data %>% fwrite(tempfile) aws_s3_store(   filename = tempfile,    bucket = 'databrew.org',    key = 'bohemiatesting-ke/test.csv',   namespace_bucket = TRUE) #> [CLOUDBREWR_LOGS]: File is uploaded with in bucket:databrew.org; key:bohemiatesting-ke/test.csv"},{"path":"/articles/cloudbrewr-three-dot-functions.html","id":"what-is-dot-dot-dot-function-in-r","dir":"Articles","previous_headings":"","what":"What is Dot Dot Dot function in R?","title":"CloudBrewR Three Dot Ellipsis Parameter","text":"means function designed take number named unnamed arguments. Just like Python *kwargs parameter","code":""},{"path":"/articles/cloudbrewr-three-dot-functions.html","id":"how-do-we-use-it-in-this-library","dir":"Articles","previous_headings":"","what":"How do we use it in this library?","title":"CloudBrewR Three Dot Ellipsis Parameter","text":"Say getting object S3 realize might need extra parameter s3 get object. aws_s3_get_object built ..., can find extra parameter can use Paws official API Docs. , able modify S3 get specific versioning needs :","code":"aws_s3_get_object(   bucket = 'databrew.org',   key = 'kwale/raw-form/reconbhousehold/reconbhousehold.csv',   VersionId = 'NaFvmYr2_E3x57xPBMmyvaK6Ar3fi1k7' # represents the 3 dots ) %>% head(5) #> $bucket #> databrew.org #>  #> $object_key #> [1] \"kwale/raw-form/reconbhousehold/reconbhousehold.csv\" #>  #> $last_modified #> [1] \"2023-01-06 21:02:12 GMT\" #>  #> $content_length #> [1] 4722148 #>  #> $version_id #> [1] \"NaFvmYr2_E3x57xPBMmyvaK6Ar3fi1k7\""},{"path":"/articles/cloudbrewr-utility-functions.html","id":"about","dir":"Articles","previous_headings":"","what":"About","title":"CloudBrewR S3 Utility Functions","text":"section covers utility function used can help daily S3 usage. utility functions CloudBrewR","code":""},{"path":"/articles/cloudbrewr-utility-functions.html","id":"get-s3-data-catalog","dir":"Articles","previous_headings":"About","what":"Get S3 Data Catalog","title":"CloudBrewR S3 Utility Functions","text":"function used get catalog files databrew.org bucket. crawl objects inside S3 folder narrow catalog search:","code":"aws_s3_get_catalog(   bucket = 'databrew.org') %>%    head(5) %>%    dplyr::select(Key, LastModified, Size) #> Warning: Expected 3 pieces. Additional pieces discarded in 64 rows [15, 16, 17, #> 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, ...]. #> Warning: Expected 3 pieces. Missing pieces filled with `NA` in 10 rows [9, 10, #> 11, 12, 81, 82, 99, 100, 101, 102]. #> # A tibble: 5 × 3 #>   Key                                                  LastModified         Size #>   <chr>                                                <dttm>              <dbl> #> 1 bohemiatesting-ke/raw-form/reconaregistration/recon… 2022-11-30 00:00:34  6744 #> 2 bohemiatesting-ke/raw-form/reconaregistration/recon… 2022-11-30 00:00:34  6744 #> 3 bohemiatesting-ke/raw-form/reconbhousehold/reconbho… 2022-11-30 00:00:34  3288 #> 4 bohemiatesting-ke/raw-form/reconbhousehold/reconbho… 2022-11-30 00:00:34  3288 #> 5 bohemiatesting-ke/raw-form/reconhh/reconhh.csv       2022-11-30 00:00:34  3089 aws_s3_get_catalog(   bucket = 'databrew.org',   Prefix = 'kwale/clean-form/') %>%    head(5) %>%    dplyr::select(Key, LastModified, Size) #> # A tibble: 5 × 3 #>   Key                                                 LastModified          Size #>   <chr>                                               <dttm>               <dbl> #> 1 kwale/clean-form/reconaregistration/reconaregistra… 2023-01-08 21:03:21 5.82e4 #> 2 kwale/clean-form/reconaregistration/reconaregistra… 2023-01-08 21:03:21 5.82e4 #> 3 kwale/clean-form/reconaregistrationtraining/recona… 2022-11-30 00:02:07 1.27e4 #> 4 kwale/clean-form/reconaregistrationtraining/recona… 2022-11-30 00:02:07 1.27e4 #> 5 kwale/clean-form/reconbhousehold/reconbhousehold.c… 2023-01-08 21:03:23 4.69e6"},{"path":"/articles/cloudbrewr-utility-functions.html","id":"get-s3-object-versioning-history","dir":"Articles","previous_headings":"About","what":"Get S3 Object Versioning History","title":"CloudBrewR S3 Utility Functions","text":"function used get object versioning history (notated VersionId) metadata","code":"aws_s3_get_object_version_history(   bucket = 'databrew.org',    key = 'kwale/raw-form/reconaregistration/reconaregistration.csv') %>%    head(5) %>%    dplyr::select(Key, Size, LastModified, VersionId) #> # A tibble: 5 × 4 #>   Key                                           Size LastModified        Versi…¹ #>   <chr>                                        <dbl> <dttm>              <chr>   #> 1 kwale/raw-form/reconaregistration/reconareg… 65764 2023-01-08 21:01:54 GTRG_E… #> 2 kwale/raw-form/reconaregistration/reconareg… 65764 2023-01-08 14:02:10 DRYWA7… #> 3 kwale/raw-form/reconaregistration/reconareg… 65764 2023-01-08 13:02:10 KtNCyc… #> 4 kwale/raw-form/reconaregistration/reconareg… 65764 2023-01-08 12:02:38 0_YjaS… #> 5 kwale/raw-form/reconaregistration/reconareg… 65764 2023-01-08 11:02:17 itca_Q… #> # … with abbreviated variable name ¹​VersionId"},{"path":"/articles/cloudbrewr-utility-functions.html","id":"get-table-directly-from-s3","dir":"Articles","previous_headings":"About","what":"Get Table Directly from S3","title":"CloudBrewR S3 Utility Functions","text":"Wrapper function get table-like data directly S3","code":"aws_s3_get_table(   bucket = 'databrew.org',    key = 'bohemiatesting-ke/raw-form/reconregistration/reconregistration.csv') %>%    head(5) %>%    dplyr::select(SubmissionDate) #> # A tibble: 5 × 1 #>   SubmissionDate      #>   <dttm>              #> 1 2022-09-20 10:54:24 #> 2 2022-07-04 19:50:22 #> 3 2022-07-04 13:03:52 #> 4 2022-07-04 12:20:32 #> 5 2022-06-30 09:55:45"},{"path":"/articles/cloudbrewr-utility-functions.html","id":"get-files-partitioned-in-folder","dir":"Articles","previous_headings":"About","what":"Get Files Partitioned in Folder","title":"CloudBrewR S3 Utility Functions","text":"working Data Lakes S3, one commons strategy save .csv files folders/partitions. One use-case storing Anomalies per Day. structured S3 partitions, able take snapshots many anomalies identified Recon, format follows: databrew.org/kwale/anomalies/anomalies-identification-history/run_date={YYYY}-{MM}-{DD} can query data rowwwise format running, indexed run_date running can also repurpose fetch specific date-range -extract partitioned files.","code":"aws_s3_get_table_ts(   bucket = 'databrew.org',    key = 'kwale/anomalies/anomalies-identification-history/') %>%    head(5) %>%    dplyr::select(run_date,type) #> # A tibble: 5 × 2 #>   run_date   type                #>   <IDate>    <chr>               #> 1 2022-12-07 recona_duplicate_id #> 2 2022-12-07 recona_duplicate_id #> 3 2022-12-07 reconb_duplicate_id #> 4 2022-12-07 reconb_duplicate_id #> 5 2022-12-07 reconb_duplicate_id aws_s3_get_table_ts(   bucket = 'databrew.org',    key = 'kwale/anomalies/anomalies-identification-history/',   date_range = c('2023-01-01', '2023-01-05')) %>%    head(5) %>%    dplyr::select(run_date,type) #> # A tibble: 5 × 2 #>   run_date   type                              #>   <IDate>    <chr>                             #> 1 2023-01-01 recona_mismatch_cha_supervise_chv #> 2 2023-01-01 recona_mismatch_cha_supervise_chv #> 3 2023-01-02 recona_mismatch_cha_supervise_chv #> 4 2023-01-02 recona_mismatch_cha_supervise_chv #> 5 2023-01-03 recona_mismatch_cha_supervise_chv"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Aryton Tediarjo. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Tediarjo (2023). cloudbrewr: DataBrew Internal Tooling AWS Data Load / Storage. R package version 0.0.0.9000.","code":"@Manual{,   title = {cloudbrewr: DataBrew Internal Tooling for AWS Data Load / Storage},   author = {Aryton Tediarjo},   year = {2023},   note = {R package version 0.0.0.9000}, }"},{"path":"/index.html","id":"cloudbrewr","dir":"","previous_headings":"","what":"DataBrew Internal Tooling for AWS Data Load / Storage","title":"DataBrew Internal Tooling for AWS Data Load / Storage","text":"@Author: atediarjo@gmail.com Internal Tooling DataBrew Cloud Storage. purpose R package help user able get, store, catalog, data efficiently cloud providers. currently supporting data stored : AWS S3 Storage TBD","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"DataBrew Internal Tooling for AWS Data Load / Storage","text":"Installation can done github installation:","code":"devtools::install_github('databrew/cloudbrewr')"},{"path":"/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"DataBrew Internal Tooling for AWS Data Load / Storage","text":"Check team Vignettes Github Pages","code":""},{"path":"/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"DataBrew Internal Tooling for AWS Data Load / Storage","text":"Coming soon","code":""},{"path":"/reference/aws_configure.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to create SSO configuration — aws_configure","title":"Function to create SSO configuration — aws_configure","text":"Create ~/.aws/config requirements SSO DataBrew AWS Accounts","code":""},{"path":"/reference/aws_configure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to create SSO configuration — aws_configure","text":"","code":"aws_configure(env)"},{"path":"/reference/aws_configure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to create SSO configuration — aws_configure","text":"env environment variables","code":""},{"path":"/reference/aws_login.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility Function to login to DataBrew AWS.\nIf user is in an interactive session, generate all the required credentials to run SSO.\nIf user is running in Terminal / bash / workflow / VM prompt to export temporary credentials — aws_login","title":"Utility Function to login to DataBrew AWS.\nIf user is in an interactive session, generate all the required credentials to run SSO.\nIf user is running in Terminal / bash / workflow / VM prompt to export temporary credentials — aws_login","text":"Utility Function login DataBrew AWS. user interactive session, generate required credentials run SSO. user running Terminal / bash / workflow / VM prompt export temporary credentials","code":""},{"path":"/reference/aws_login.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility Function to login to DataBrew AWS.\nIf user is in an interactive session, generate all the required credentials to run SSO.\nIf user is running in Terminal / bash / workflow / VM prompt to export temporary credentials — aws_login","text":"","code":"aws_login(pipeline_stage = \"production\")"},{"path":"/reference/aws_login.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility Function to login to DataBrew AWS.\nIf user is in an interactive session, generate all the required credentials to run SSO.\nIf user is running in Terminal / bash / workflow / VM prompt to export temporary credentials — aws_login","text":"pipeline_stage (optional) choose production/develop stage","code":""},{"path":"/reference/aws_login.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utility Function to login to DataBrew AWS.\nIf user is in an interactive session, generate all the required credentials to run SSO.\nIf user is running in Terminal / bash / workflow / VM prompt to export temporary credentials — aws_login","text":"metadata AWS STS authentication (Account, Role)","code":""},{"path":"/reference/aws_namespace.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to namespace bucket based on prod/dev environment — aws_namespace","title":"Function to namespace bucket based on prod/dev environment — aws_namespace","text":"Function namespace bucket based prod/dev environment","code":""},{"path":"/reference/aws_namespace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to namespace bucket based on prod/dev environment — aws_namespace","text":"","code":"aws_namespace(bucket)"},{"path":"/reference/aws_namespace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to namespace bucket based on prod/dev environment — aws_namespace","text":"bucket databrew s3 bucket","code":""},{"path":"/reference/aws_namespace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to namespace bucket based on prod/dev environment — aws_namespace","text":"namspaced buckeet","code":""},{"path":"/reference/aws_s3_create_bucket.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to create S3 bucket — aws_s3_create_bucket","title":"Function to create S3 bucket — aws_s3_create_bucket","text":"create S3 bucket via API","code":""},{"path":"/reference/aws_s3_create_bucket.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to create S3 bucket — aws_s3_create_bucket","text":"","code":"aws_s3_create_bucket(bucket, namespace_bucket = TRUE, ...)"},{"path":"/reference/aws_s3_create_bucket.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to create S3 bucket — aws_s3_create_bucket","text":"bucket s3 bucket namespace_bucket namespace bucket prod/dev ... additional parameter passed s3 create_bucket endpoint","code":""},{"path":"/reference/aws_s3_get_catalog.html","id":null,"dir":"Reference","previous_headings":"","what":"Get DataBrew S3 object catalog — aws_s3_get_catalog","title":"Get DataBrew S3 object catalog — aws_s3_get_catalog","text":"Get catalog files used S3","code":""},{"path":"/reference/aws_s3_get_catalog.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get DataBrew S3 object catalog — aws_s3_get_catalog","text":"","code":"aws_s3_get_catalog(bucket, namespace_bucket = TRUE, ...)"},{"path":"/reference/aws_s3_get_catalog.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get DataBrew S3 object catalog — aws_s3_get_catalog","text":"bucket s3 bucket namespace_bucket boolean create namespace bucket, set FALSE override bucket namespace ... additional parameter S3 get object","code":""},{"path":"/reference/aws_s3_get_catalog.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get DataBrew S3 object catalog — aws_s3_get_catalog","text":"tibble S3 file catalog","code":""},{"path":"/reference/aws_s3_get_object.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Object in DataBrew S3 — aws_s3_get_object","title":"Get Object in DataBrew S3 — aws_s3_get_object","text":"Get Object DataBrew S3","code":""},{"path":"/reference/aws_s3_get_object.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Object in DataBrew S3 — aws_s3_get_object","text":"","code":"aws_s3_get_object(bucket, key, namespace_bucket = TRUE, ...)"},{"path":"/reference/aws_s3_get_object.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Object in DataBrew S3 — aws_s3_get_object","text":"bucket s3 bucket key s3 object key namespace_bucket boolean create namespace bucket, set FALSE override bucket namespace ... additional parameter S3 get object","code":""},{"path":"/reference/aws_s3_get_object.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Object in DataBrew S3 — aws_s3_get_object","text":"list object s3 metadata file location","code":""},{"path":"/reference/aws_s3_get_object_version_history.html","id":null,"dir":"Reference","previous_headings":"","what":"Get object version history in s3 — aws_s3_get_object_version_history","title":"Get object version history in s3 — aws_s3_get_object_version_history","text":"Get object version change history","code":""},{"path":"/reference/aws_s3_get_object_version_history.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get object version history in s3 — aws_s3_get_object_version_history","text":"","code":"aws_s3_get_object_version_history(bucket, key, namespace_bucket = TRUE, ...)"},{"path":"/reference/aws_s3_get_object_version_history.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get object version history in s3 — aws_s3_get_object_version_history","text":"bucket s3 bucket key s3 object key namespace_bucket boolean create namespace bucket, set FALSE override bucket namespace ... additional parameter S3 get object","code":""},{"path":"/reference/aws_s3_get_object_version_history.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get object version history in s3 — aws_s3_get_object_version_history","text":"tibble S3 object version history","code":""},{"path":"/reference/aws_s3_get_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to retrieve s3 object directly into table — aws_s3_get_table","title":"Function to retrieve s3 object directly into table — aws_s3_get_table","text":"wrapper function transform s3 tibble","code":""},{"path":"/reference/aws_s3_get_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to retrieve s3 object directly into table — aws_s3_get_table","text":"","code":"aws_s3_get_table(bucket, key, namespace_bucket = TRUE, ...)"},{"path":"/reference/aws_s3_get_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to retrieve s3 object directly into table — aws_s3_get_table","text":"bucket s3 bucket key s3 object key namespace_bucket boolean create namespace bucket, set FALSE override bucket namespace ... additional parameter S3 get object","code":""},{"path":"/reference/aws_s3_get_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to retrieve s3 object directly into table — aws_s3_get_table","text":"tibble data-frame s3 object","code":""},{"path":"/reference/aws_s3_get_table_ts.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to retrieve S3 folder-partitioned table into time-series data — aws_s3_get_table_ts","title":"Function to retrieve S3 folder-partitioned table into time-series data — aws_s3_get_table_ts","text":"Wrapper bind folder-partitioned table time-series, indexed run_date","code":""},{"path":"/reference/aws_s3_get_table_ts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to retrieve S3 folder-partitioned table into time-series data — aws_s3_get_table_ts","text":"","code":"aws_s3_get_table_ts(   bucket,   key,   namespace_bucket = TRUE,   date_range = NULL,   ... )"},{"path":"/reference/aws_s3_get_table_ts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to retrieve S3 folder-partitioned table into time-series data — aws_s3_get_table_ts","text":"bucket s3 bucket key object key namespace_bucket boolean bucket namespacing, set FALSE override namespace date_range date range min/max date partition ... argument s3 api list_objects_v2","code":""},{"path":"/reference/aws_s3_get_table_ts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to retrieve S3 folder-partitioned table into time-series data — aws_s3_get_table_ts","text":"tibble dataframe run-date index","code":""},{"path":"/reference/aws_s3_store.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to store object to S3 — aws_s3_store","title":"Function to store object to S3 — aws_s3_store","text":"Store object S3 (limited <=5GB per object)","code":""},{"path":"/reference/aws_s3_store.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to store object to S3 — aws_s3_store","text":"","code":"aws_s3_store(filename, bucket, key, namespace_bucket = TRUE, ...)"},{"path":"/reference/aws_s3_store.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to store object to S3 — aws_s3_store","text":"filename filename bucket s3 bucket key s3 object key namespace_bucket boolean whether namespace bucket based prod/dev environment ... additional parameter passed s3 put_object","code":""},{"path":"/reference/aws_s3_sync.html","id":null,"dir":"Reference","previous_headings":"","what":"bucket, key, — aws_s3_sync","title":"bucket, key, — aws_s3_sync","text":"bucket, key,","code":""},{"path":"/reference/aws_s3_sync.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"bucket, key, — aws_s3_sync","text":"","code":"aws_s3_sync(manifest)"},{"path":"/reference/aws_sso_authenticate.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to initiate SSO authentication — aws_sso_authenticate","title":"Function to initiate SSO authentication — aws_sso_authenticate","text":"Instantiate SSO connection using internet browser","code":""},{"path":"/reference/aws_sso_authenticate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to initiate SSO authentication — aws_sso_authenticate","text":"","code":"aws_sso_authenticate(profile_name)"},{"path":"/reference/aws_sso_authenticate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to initiate SSO authentication — aws_sso_authenticate","text":"profile_name profile name set prod/dev","code":""},{"path":"/reference/call_cloudbrewr_stage_env_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to get prod/dev stage environment variables,\nuse this to retrieve environment variables used for\nS3 bucket namespace and profile name to your environment variables. — call_cloudbrewr_stage_env_variables","title":"Function to get prod/dev stage environment variables,\nuse this to retrieve environment variables used for\nS3 bucket namespace and profile name to your environment variables. — call_cloudbrewr_stage_env_variables","text":"Function get prod/dev stage environment variables, use retrieve environment variables used S3 bucket namespace profile name environment variables.","code":""},{"path":"/reference/call_cloudbrewr_stage_env_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to get prod/dev stage environment variables,\nuse this to retrieve environment variables used for\nS3 bucket namespace and profile name to your environment variables. — call_cloudbrewr_stage_env_variables","text":"","code":"call_cloudbrewr_stage_env_variables(pipeline_stage)"},{"path":"/reference/call_cloudbrewr_stage_env_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to get prod/dev stage environment variables,\nuse this to retrieve environment variables used for\nS3 bucket namespace and profile name to your environment variables. — call_cloudbrewr_stage_env_variables","text":"pipeline_stage choose production/develop stage","code":""},{"path":"/reference/check_aws_access.html","id":null,"dir":"Reference","previous_headings":"","what":"Check aws access via STS — check_aws_access","title":"Check aws access via STS — check_aws_access","text":"Check aws access via STS","code":""},{"path":"/reference/check_aws_access.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check aws access via STS — check_aws_access","text":"","code":"check_aws_access()"},{"path":"/reference/check_aws_access.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check aws access via STS — check_aws_access","text":"metadata STS caller identity","code":""},{"path":"/reference/check_aws_environment_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to check AWS environment variables — check_aws_environment_variables","title":"Function to check AWS environment variables — check_aws_environment_variables","text":"send user message completion AWS Environment Variables","code":""},{"path":"/reference/check_aws_environment_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to check AWS environment variables — check_aws_environment_variables","text":"","code":"check_aws_environment_variables()"}]
